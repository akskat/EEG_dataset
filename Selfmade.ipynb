{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00e7ff73",
   "metadata": {},
   "source": [
    "# EEG Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e244f1b5",
   "metadata": {},
   "source": [
    "## Converting Files to CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e3d0462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined CSV: ./csv_output/Person1Recording1.csv\n",
      "Saved combined CSV: ./csv_output/Person1Recording2.csv\n",
      "Saved combined CSV: ./csv_output/Person1Recording3.csv\n",
      "Saved combined CSV: ./csv_output/Person1Recording3.csv\n",
      "Saved combined CSV: ./csv_output/Person2Recording1.csv\n",
      "Saved combined CSV: ./csv_output/Person2Recording2.csv\n",
      "Saved combined CSV: ./csv_output/Person2Recording3.csv\n",
      "Saved combined CSV: ./csv_output/Person3Recording1.csv\n",
      "Saved combined CSV: ./csv_output/Person3Recording2.csv\n",
      "Saved combined CSV: ./csv_output/Person3Recording3.csv\n",
      "Saved combined CSV: ./csv_output/Person4Recording1.csv\n",
      "Saved combined CSV: ./csv_output/Person4Recording2.csv\n",
      "Saved combined CSV: ./csv_output/Person5Recording4.csv\n",
      "Saved combined CSV: ./csv_output/Person6Recording4.csv\n",
      "Saved combined CSV: ./csv_output/Person6Recording5.csv\n",
      "Saved combined CSV: ./csv_output/Person6Recording6.csv\n",
      "Saved combined CSV: ./csv_output/Person7Recording7.csv\n",
      "Saved combined CSV: ./csv_output/Person8Recording8.csv\n"
     ]
    }
   ],
   "source": [
    "# Notebook: EEG File Converter to CSV with Integrated Annotations\n",
    "import os\n",
    "import mne\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress MNE warnings\n",
    "mne.set_log_level('ERROR')\n",
    "\n",
    "# Define paths\n",
    "root_path = './data/selfmade_dataset/'       # adjust if necessary\n",
    "output_path = './csv_output/'\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Channels to mark as misc\n",
    "misc_chs = ['Aux1', 'Aux2', 'x_dir', 'y_dir', 'z_dir']\n",
    "\n",
    "# Iterate over Person and Recording folders\n",
    "for person_dir in sorted(os.listdir(root_path)):\n",
    "    person_path = os.path.join(root_path, person_dir)\n",
    "    if not os.path.isdir(person_path):\n",
    "        continue\n",
    "\n",
    "    for recording_dir in sorted(os.listdir(person_path)):\n",
    "        recording_path = os.path.join(person_path, recording_dir)\n",
    "        if not os.path.isdir(recording_path):\n",
    "            continue\n",
    "\n",
    "        # Process .vhdr files\n",
    "        for file in sorted(os.listdir(recording_path)):\n",
    "            if not file.endswith('.vhdr'):\n",
    "                continue\n",
    "\n",
    "            vhdr_path = os.path.join(recording_path, file)\n",
    "            basename = file[:-5]  # strip .vhdr\n",
    "\n",
    "            # Fix .vhdr references\n",
    "            with open(vhdr_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "            with open(vhdr_path, 'w', encoding='utf-8') as f:\n",
    "                for line in lines:\n",
    "                    if line.startswith('DataFile='):\n",
    "                        f.write(f'DataFile={basename}.eeg\\n')\n",
    "                    elif line.startswith('MarkerFile='):\n",
    "                        f.write(f'MarkerFile={basename}.vmrk\\n')\n",
    "                    else:\n",
    "                        f.write(line)\n",
    "\n",
    "            # Load raw data, specifying eog as empty list and misc channels\n",
    "            raw = mne.io.read_raw_brainvision(\n",
    "                vhdr_path,\n",
    "                preload=True,\n",
    "                eog=[],\n",
    "                misc=misc_chs\n",
    "            )\n",
    "\n",
    "            # Convert to DataFrame\n",
    "            df = raw.to_data_frame()\n",
    "\n",
    "            # Add annotation column, default ''\n",
    "            df['annotation'] = ''\n",
    "            if raw.annotations and len(raw.annotations) > 0:\n",
    "                for onset, duration, desc in zip(raw.annotations.onset,\n",
    "                                                 raw.annotations.duration,\n",
    "                                                 raw.annotations.description):\n",
    "                    mask = (df['time'] >= onset) & (df['time'] < onset + duration)\n",
    "                    df.loc[mask, 'annotation'] = desc\n",
    "\n",
    "            # Save combined CSV\n",
    "            out_csv = os.path.join(output_path, f'{basename}.csv')\n",
    "            df.to_csv(out_csv, index=False)\n",
    "            print(f'Saved combined CSV: {out_csv}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743f5df1",
   "metadata": {},
   "source": [
    "## Extend annotations for all rows and clean annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e039ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated annotations in: ./csv_output/Person1Recording1.csv\n",
      "Updated annotations in: ./csv_output/Person1Recording2.csv\n",
      "Updated annotations in: ./csv_output/Person1Recording3.csv\n",
      "Updated annotations in: ./csv_output/Person2Recording1.csv\n",
      "Updated annotations in: ./csv_output/Person2Recording2.csv\n",
      "Updated annotations in: ./csv_output/Person2Recording3.csv\n",
      "Updated annotations in: ./csv_output/Person3Recording1.csv\n",
      "Updated annotations in: ./csv_output/Person3Recording2.csv\n",
      "Updated annotations in: ./csv_output/Person3Recording3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksel\\AppData\\Local\\Temp\\ipykernel_59716\\794490201.py:7: DtypeWarning: Columns (38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated annotations in: ./csv_output/Person4Recording1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksel\\AppData\\Local\\Temp\\ipykernel_59716\\794490201.py:7: DtypeWarning: Columns (38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated annotations in: ./csv_output/Person4Recording2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksel\\AppData\\Local\\Temp\\ipykernel_59716\\794490201.py:7: DtypeWarning: Columns (36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated annotations in: ./csv_output/Person5Recording4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksel\\AppData\\Local\\Temp\\ipykernel_59716\\794490201.py:7: DtypeWarning: Columns (36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated annotations in: ./csv_output/Person6Recording4.csv\n",
      "Updated annotations in: ./csv_output/Person6Recording5.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksel\\AppData\\Local\\Temp\\ipykernel_59716\\794490201.py:7: DtypeWarning: Columns (36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated annotations in: ./csv_output/Person6Recording6.csv\n",
      "Updated annotations in: ./csv_output/Person7Recording7.csv\n",
      "Updated annotations in: ./csv_output/Person8Recording8.csv\n"
     ]
    }
   ],
   "source": [
    "import os, pandas as pd, numpy as np\n",
    "\n",
    "for file in sorted(os.listdir(output_path)):\n",
    "    if not file.endswith('.csv'):\n",
    "        continue\n",
    "    csv_file = os.path.join(output_path, file)\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Replace empty strings with NaN for ffill\n",
    "    df['annotation'] = df['annotation'].replace('', np.nan)\n",
    "    # Remove 'Stimulus/' prefix\n",
    "    df['annotation'] = df['annotation'].str.replace(r'^Stimulus/', '', regex=True)\n",
    "    # Forward-fill\n",
    "    df['annotation'] = df['annotation'].ffill()\n",
    "    df['annotation'] = df['annotation'].fillna('')\n",
    "\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f'Updated annotations in: {csv_file}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c96a739",
   "metadata": {},
   "source": [
    "## Add columns for Person and Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f5c544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Person and Recording columns in: ./csv_output/Person1Recording1.csv\n",
      "Added Person and Recording columns in: ./csv_output/Person1Recording2.csv\n",
      "Added Person and Recording columns in: ./csv_output/Person1Recording3.csv\n",
      "Added Person and Recording columns in: ./csv_output/Person2Recording1.csv\n",
      "Added Person and Recording columns in: ./csv_output/Person2Recording2.csv\n",
      "Added Person and Recording columns in: ./csv_output/Person2Recording3.csv\n",
      "Added Person and Recording columns in: ./csv_output/Person3Recording1.csv\n",
      "Added Person and Recording columns in: ./csv_output/Person3Recording2.csv\n",
      "Added Person and Recording columns in: ./csv_output/Person3Recording3.csv\n",
      "Added Person and Recording columns in: ./csv_output/Person4Recording1.csv\n",
      "Added Person and Recording columns in: ./csv_output/Person4Recording2.csv\n",
      "Added Person and Recording columns in: ./csv_output/Person5Recording4.csv\n",
      "Added Person and Recording columns in: ./csv_output/Person6Recording4.csv\n",
      "Added Person and Recording columns in: ./csv_output/Person6Recording5.csv\n",
      "Added Person and Recording columns in: ./csv_output/Person6Recording6.csv\n",
      "Added Person and Recording columns in: ./csv_output/Person7Recording7.csv\n",
      "Added Person and Recording columns in: ./csv_output/Person8Recording8.csv\n"
     ]
    }
   ],
   "source": [
    "import os, re, pandas as pd\n",
    "\n",
    "for file in sorted(os.listdir(output_path)):\n",
    "    if not file.endswith('.csv'):\n",
    "        continue\n",
    "    csv_file = os.path.join(output_path, file)\n",
    "    m = re.match(r'Person(\\d+)Recording(\\d+)\\.csv$', file)\n",
    "    if not m:\n",
    "        print(f\"Filename does not match pattern: {file}\")\n",
    "        continue\n",
    "    person_num, recording_num = map(int, m.groups())\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df.insert(0, 'Recording', recording_num)\n",
    "    df.insert(0, 'Person',    person_num)\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f'Added Person and Recording columns in: {csv_file}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5827f",
   "metadata": {},
   "source": [
    "## Remove New Segment, START, END annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf41395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed unwanted annotations in: ./csv_output/Person1Recording1.csv\n",
      "Removed unwanted annotations in: ./csv_output/Person1Recording2.csv\n",
      "Removed unwanted annotations in: ./csv_output/Person1Recording3.csv\n",
      "Removed unwanted annotations in: ./csv_output/Person2Recording1.csv\n",
      "Removed unwanted annotations in: ./csv_output/Person2Recording2.csv\n",
      "Removed unwanted annotations in: ./csv_output/Person2Recording3.csv\n",
      "Removed unwanted annotations in: ./csv_output/Person3Recording1.csv\n",
      "Removed unwanted annotations in: ./csv_output/Person3Recording2.csv\n",
      "Removed unwanted annotations in: ./csv_output/Person3Recording3.csv\n",
      "Removed unwanted annotations in: ./csv_output/Person4Recording1.csv\n",
      "Removed unwanted annotations in: ./csv_output/Person4Recording2.csv\n",
      "Removed unwanted annotations in: ./csv_output/Person5Recording4.csv\n",
      "Removed unwanted annotations in: ./csv_output/Person6Recording4.csv\n",
      "Removed unwanted annotations in: ./csv_output/Person6Recording5.csv\n",
      "Removed unwanted annotations in: ./csv_output/Person6Recording6.csv\n",
      "Removed unwanted annotations in: ./csv_output/Person7Recording7.csv\n",
      "Removed unwanted annotations in: ./csv_output/Person8Recording8.csv\n"
     ]
    }
   ],
   "source": [
    "import os, pandas as pd\n",
    "\n",
    "unwanted = ['New Segment/', 'START', 'END']\n",
    "for file in sorted(os.listdir(output_path)):\n",
    "    if not file.endswith('.csv'):\n",
    "        continue\n",
    "    csv_file = os.path.join(output_path, file)\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    df = df[~df['annotation'].isin(unwanted)]\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f'Removed unwanted annotations in: {csv_file}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d88e11",
   "metadata": {},
   "source": [
    "## Replace lost-sample marker with REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c0c3cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oppdatert annotering i Person1Recording1.csv\n",
      "Oppdatert annotering i Person1Recording2.csv\n",
      "Oppdatert annotering i Person1Recording3.csv\n",
      "Oppdatert annotering i Person2Recording1.csv\n",
      "Oppdatert annotering i Person2Recording2.csv\n",
      "Oppdatert annotering i Person2Recording3.csv\n",
      "Oppdatert annotering i Person3Recording1.csv\n",
      "Oppdatert annotering i Person3Recording2.csv\n",
      "Oppdatert annotering i Person3Recording3.csv\n",
      "Oppdatert annotering i Person4Recording1.csv\n",
      "Oppdatert annotering i Person4Recording2.csv\n",
      "Oppdatert annotering i Person5Recording4.csv\n",
      "Oppdatert annotering i Person6Recording4.csv\n",
      "Oppdatert annotering i Person6Recording5.csv\n",
      "Oppdatert annotering i Person6Recording6.csv\n",
      "Oppdatert annotering i Person7Recording7.csv\n",
      "Oppdatert annotering i Person8Recording8.csv\n"
     ]
    }
   ],
   "source": [
    "import os, pandas as pd\n",
    "\n",
    "for fname in sorted(os.listdir(output_path)):\n",
    "    if not fname.endswith('.csv'):\n",
    "        continue\n",
    "    fullpath = os.path.join(output_path, fname)\n",
    "    df = pd.read_csv(fullpath)\n",
    "\n",
    "    df['annotation'] = df['annotation'].replace(\n",
    "        'New Segment/LostSamples: 1', 'REST'\n",
    "    )\n",
    "    df.to_csv(fullpath, index=False)\n",
    "    print(f\"Oppdatert annotering i {fname}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8955ea0-4ce8-429c-a6e2-26765ca227a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording durations:\n",
      "\n",
      "Person1Recording1.csv: 4 min 43 sec\n",
      "Person1Recording2.csv: 4 min 43 sec\n",
      "Person1Recording3.csv: 4 min 43 sec\n",
      "Person2Recording1.csv: 4 min 43 sec\n",
      "Person2Recording2.csv: 4 min 43 sec\n",
      "Person2Recording3.csv: 4 min 43 sec\n",
      "Person3Recording1.csv: 4 min 43 sec\n",
      "Person3Recording2.csv: 4 min 43 sec\n",
      "Person3Recording3.csv: 4 min 43 sec\n",
      "Person4Recording1.csv: 14 min 10 sec\n",
      "Person4Recording2.csv: 14 min 10 sec\n",
      "Person5Recording4.csv: 14 min 19 sec\n",
      "Person6Recording4.csv: 4 min 53 sec\n",
      "Person6Recording5.csv: 4 min 53 sec\n",
      "Person6Recording6.csv: 4 min 53 sec\n",
      "Person7Recording7.csv: 4 min 53 sec\n",
      "Person8Recording8.csv: 4 min 53 sec\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Recording durations:\\n\")\n",
    "\n",
    "for file in sorted(os.listdir(output_path)):\n",
    "    if not file.endswith('.csv'):\n",
    "        continue\n",
    "\n",
    "    csv_file = os.path.join(output_path, file)\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Duration is last time value minus first time value\n",
    "    start_time = df['time'].iloc[0]\n",
    "    end_time = df['time'].iloc[-1]\n",
    "    duration_sec = end_time - start_time\n",
    "\n",
    "    minutes = int(duration_sec // 60)\n",
    "    seconds = int(duration_sec % 60)\n",
    "\n",
    "    print(f\"{file}: {minutes} min {seconds} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c4f243-1d9c-48f0-ae4e-cbf16bd22566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
